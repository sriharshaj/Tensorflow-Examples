{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/digit-recognizer\n",
    "data = np.genfromtxt('./train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preparing Input Data\n",
    "X = data[:,1:].astype(np.float32)\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preparing Lablels Data\n",
    "y = data[:,0:1]\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y = enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=10)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=0.5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_classes = 10\n",
    "learning_rate = 0.00005\n",
    "batch_size = 128\n",
    "training_epochs = 40\n",
    "n_hidden_layer_1 = 128\n",
    "n_hidden_layer_2 = 256\n",
    "dropout_prob_1 = 0.6\n",
    "dropout_prob_2 = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'hidden_layer_1': tf.Variable(tf.random_normal([n_input, n_hidden_layer_1])),\n",
    "    'hidden_layer_2': tf.Variable(tf.random_normal([n_hidden_layer_1, n_hidden_layer_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer_2, n_classes]))\n",
    "}\n",
    "baises = {\n",
    "    'hidden_layer_1': tf.Variable(tf.random_normal([n_hidden_layer_1])),\n",
    "    'hidden_layer_2': tf.Variable(tf.random_normal([n_hidden_layer_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MODEL\n",
    "X_t = tf.placeholder(tf.float32, [None, n_input])\n",
    "y_t = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob_1 = tf.placeholder('float')\n",
    "keep_prob_2 = tf.placeholder('float')\n",
    "hidden_layer_1 = tf.nn.relu(tf.add(tf.matmul(X_t, weights['hidden_layer_1']), baises['hidden_layer_1']))\n",
    "hidden_layer_1 = tf.nn.dropout(hidden_layer_1, keep_prob_1)\n",
    "hidden_layer_2 = tf.nn.relu(tf.add(tf.matmul(hidden_layer_1, weights['hidden_layer_2']), baises['hidden_layer_2']))\n",
    "hidden_layer_2 = tf.nn.dropout(hidden_layer_2, keep_prob_2)\n",
    "logits = tf.add(tf.matmul(hidden_layer_2, weights['out']), baises['out'])\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_t))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y_t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def split_into_batches(X, y, batch_size=128):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    output_batches = []\n",
    "    sample_size = int(X.shape[0])\n",
    "    X_s, y_s = shuffle(X, y)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [X_s[start_i:end_i], y_s[start_i:end_i]]\n",
    "        output_batches.append(batch)\n",
    "    return output_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n",
      "Epoch 0   - Validation accuracy: 0.12904761731624603 Training accuracy 0.1405952423810959\n",
      "Epoch 1   - Validation accuracy: 0.17499999701976776 Training accuracy 0.18211309611797333\n",
      "Epoch 2   - Validation accuracy: 0.2202380895614624 Training accuracy 0.22630952298641205\n",
      "Epoch 3   - Validation accuracy: 0.2669047713279724 Training accuracy 0.275773823261261\n",
      "Epoch 4   - Validation accuracy: 0.31857141852378845 Training accuracy 0.3288392722606659\n",
      "Epoch 5   - Validation accuracy: 0.3697619140148163 Training accuracy 0.37788689136505127\n",
      "Epoch 6   - Validation accuracy: 0.4166666567325592 Training accuracy 0.4263392984867096\n",
      "Epoch 7   - Validation accuracy: 0.4642857015132904 Training accuracy 0.470714271068573\n",
      "Epoch 8   - Validation accuracy: 0.4985714256763458 Training accuracy 0.5092262029647827\n",
      "Epoch 9   - Validation accuracy: 0.528333306312561 Training accuracy 0.5406547784805298\n",
      "Epoch 10  - Validation accuracy: 0.5573809742927551 Training accuracy 0.5685119032859802\n",
      "Epoch 11  - Validation accuracy: 0.579285740852356 Training accuracy 0.5924107432365417\n",
      "Epoch 12  - Validation accuracy: 0.6002380847930908 Training accuracy 0.6119047403335571\n",
      "Epoch 13  - Validation accuracy: 0.619523823261261 Training accuracy 0.6296131014823914\n",
      "Epoch 14  - Validation accuracy: 0.6340476274490356 Training accuracy 0.6451785564422607\n",
      "Epoch 15  - Validation accuracy: 0.653333306312561 Training accuracy 0.6576488018035889\n",
      "Epoch 16  - Validation accuracy: 0.6680952310562134 Training accuracy 0.6695238351821899\n",
      "Epoch 17  - Validation accuracy: 0.6797618865966797 Training accuracy 0.6792857050895691\n",
      "Epoch 18  - Validation accuracy: 0.6883333325386047 Training accuracy 0.6880357265472412\n",
      "Epoch 19  - Validation accuracy: 0.6938095092773438 Training accuracy 0.696488082408905\n",
      "Epoch 20  - Validation accuracy: 0.700952410697937 Training accuracy 0.7052381038665771\n",
      "Epoch 21  - Validation accuracy: 0.7092857360839844 Training accuracy 0.7124999761581421\n",
      "Epoch 22  - Validation accuracy: 0.7135714292526245 Training accuracy 0.7185118794441223\n",
      "Epoch 23  - Validation accuracy: 0.7188095450401306 Training accuracy 0.7234821319580078\n",
      "Epoch 24  - Validation accuracy: 0.7257142663002014 Training accuracy 0.7292559742927551\n",
      "Epoch 25  - Validation accuracy: 0.7311905026435852 Training accuracy 0.7338690757751465\n",
      "Epoch 26  - Validation accuracy: 0.7352380752563477 Training accuracy 0.7389583587646484\n",
      "Epoch 27  - Validation accuracy: 0.7392857074737549 Training accuracy 0.7432440519332886\n",
      "Epoch 28  - Validation accuracy: 0.7430952191352844 Training accuracy 0.7461309432983398\n",
      "Epoch 29  - Validation accuracy: 0.746666669845581 Training accuracy 0.7490773797035217\n",
      "Epoch 30  - Validation accuracy: 0.7483333349227905 Training accuracy 0.7525892853736877\n",
      "Epoch 31  - Validation accuracy: 0.753333330154419 Training accuracy 0.7556547522544861\n",
      "Epoch 32  - Validation accuracy: 0.7552381157875061 Training accuracy 0.7584226131439209\n",
      "Epoch 33  - Validation accuracy: 0.755476176738739 Training accuracy 0.7594345211982727\n",
      "Epoch 34  - Validation accuracy: 0.7578571438789368 Training accuracy 0.7613393068313599\n",
      "Epoch 35  - Validation accuracy: 0.7604761719703674 Training accuracy 0.7632440328598022\n",
      "Epoch 36  - Validation accuracy: 0.7616666555404663 Training accuracy 0.7643154859542847\n",
      "Epoch 37  - Validation accuracy: 0.7633333206176758 Training accuracy 0.7658631205558777\n",
      "Epoch 38  - Validation accuracy: 0.7654761672019958 Training accuracy 0.7664880752563477\n",
      "Epoch 39  - Validation accuracy: 0.7649999856948853 Training accuracy 0.7675595283508301\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Started Training')\n",
    "    for epoch in range(training_epochs):\n",
    "        batches = split_into_batches(X_train, y_train, batch_size=batch_size)\n",
    "        for [batch_X, batch_y] in batches:\n",
    "            sess.run(optimizer, feed_dict={X_t: batch_X, y_t: batch_y, keep_prob_1: dropout_prob_1, keep_prob_2: dropout_prob_2})\n",
    "        valid_accuracy = sess.run(accuracy, feed_dict={X_t: X_val, y_t: y_val, keep_prob_1: 1.0, keep_prob_2: 1.0})\n",
    "        training_accuracy = sess.run(accuracy, feed_dict={X_t: X_train, y_t: y_train, keep_prob_1: 1.0, keep_prob_2: 1.0})\n",
    "        print('Epoch {:<3} - Validation accuracy: {} Training accuracy {}'.format(epoch, valid_accuracy, training_accuracy))\n",
    "    saver.save(sess, './mnist.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-149.26896667  517.29394531  118.0597229    88.37108612   26.54593277\n",
      "    -8.07290077 -178.22814941  -81.26624298  -29.87822151  -15.71733761]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './mnist.ckpt')\n",
    "    print(sess.run(logits, feed_dict={X_t: X_test[0:1], keep_prob_1: 1.0, keep_prob_2: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-315.43103027  688.57531738   86.82846832  167.62110901 -719.04998779\n",
      "   207.35830688 -196.04437256 -182.35073853   46.22846985 -147.48817444]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './mnist.ckpt')\n",
    "    print(sess.run(logits, feed_dict={X_t: X_test[0:1], keep_prob_1: 1.0, keep_prob_2: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
